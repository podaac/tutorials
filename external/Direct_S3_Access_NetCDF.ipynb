{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3781b95e",
   "metadata": {},
   "source": [
    "# How to Access Data Directly in Cloud (netCDF)\n",
    "\n",
    "imported on: **2023-02-27**\n",
    "\n",
    "<p>This notebook is from NASA Openscapes 2021 Cloud Hackathon Repository.</p>\n",
    "\n",
    "> The original source for this document is [https://github.com/NASA-Openscapes/2021-Cloud-Workshop-AGU/blob/main/how-tos/Multi-File_Direct_S3_Access_NetCDF_Example.ipynb](https://github.com/NASA-Openscapes/2021-Cloud-Workshop-AGU/blob/main/how-tos/Multi-File_Direct_S3_Access_NetCDF_Example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-banking",
   "metadata": {},
   "source": [
    "# Accessing Multiple NetCDF4/HDF5 Files - S3 Direct Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-singing",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we will access monthly sea surface height from ECCO V4r4 (10.5067/ECG5D-SSH44). The data are provided as a time series of monthly netCDFs on a 0.5-degree latitude/longitude grid.\n",
    "\n",
    "We will access the data from inside the AWS cloud (us-west-2 region, specifically) and load a time series made of multiple netCDF datasets into an `xarray` `dataset`. This approach leverages S3 native protocols for efficient access to the data.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "### 1. AWS instance running in us-west-2\n",
    "\n",
    "NASA Earthdata Cloud data in S3 can be directly accessed via temporary credentials; this access is limited to requests made within the US West (Oregon) (code: us-west-2) AWS region.\n",
    "\n",
    "### 2. Earthdata Login\n",
    "\n",
    "An Earthdata Login account is required to access data, as well as discover restricted data, from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n",
    "\n",
    "### 3. netrc File\n",
    "\n",
    "You will need a netrc file containing your NASA Earthdata Login credentials in order to execute the notebooks. A netrc file can be created manually within text editor and saved to your home directory. For additional information see: [Authentication for NASA Earthdata](https://nasa-openscapes.github.io/2021-Cloud-Hackathon/tutorials/04_NASA_Earthdata_Authentication.html#authentication-via-netrc-file).\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- how to retrieve temporary S3 credentials for in-region direct S3 bucket access\n",
    "- how to define a dataset of interest and find netCDF files in S3 bucket\n",
    "- how to perform in-region direct access of ECCO_L4_SSH_05DEG_MONTHLY_V4R4 data in S3\n",
    "- how to plot the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc75360-8e7f-43d7-a5f6-f8dd58ae7307",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51cc83-bf15-4d20-a9d8-59bfb31d0b02",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-investment",
   "metadata": {},
   "source": [
    "## Get Temporary AWS Credentials\n",
    "\n",
    "Direct S3 access is achieved by passing NASA supplied temporary credentials to AWS so we can interact with S3 objects from applicable Earthdata Cloud buckets. For now, each NASA DAAC has different AWS credentials endpoints. Below are some of the credential endpoints to various DAACs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_cred_endpoint = {\n",
    "    'podaac':'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
    "    'gesdisc': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
    "    'lpdaac':'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials',\n",
    "    'ornldaac': 'https://data.ornldaac.earthdata.nasa.gov/s3credentials',\n",
    "    'ghrcdaac': 'https://data.ghrc.earthdata.nasa.gov/s3credentials'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db330d6-0454-4501-92ce-beadd6da88d1",
   "metadata": {},
   "source": [
    "Create a function to make a request to an endpoint for temporary credentials. Remember, each DAAC has their own endpoint and credentials are not usable for cloud data from other DAACs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad8758-e013-4cfc-8db4-21b44eb868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_creds(provider):\n",
    "    return requests.get(s3_cred_endpoint[provider]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5ddce-963e-44f3-a0ea-985f9322ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_creds_req = get_temp_creds('podaac')\n",
    "#temp_creds_req"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a299c2f-5a5e-4fea-bdbf-6713429cc51e",
   "metadata": {},
   "source": [
    "## Set up an `s3fs` session for Direct Access\n",
    "\n",
    "`s3fs` sessions are used for authenticated access to s3 bucket and allows for typical file-system style operations. Below we create session by passing in the temporary credentials we recieved from our temporary credentials endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f8c3f-9f21-4d6d-8935-5937bac40937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'],\n",
    "                          client_kwargs={'region_name':'us-west-2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-ballot",
   "metadata": {},
   "source": [
    "In this example we're interested in the ECCO data collection from NASA's PO.DAAC in Earthdata Cloud. In this case it's the following string that unique identifies the collection of monthly, 0.5-degree sea surface height data (ECCO_L4_SSH_05DEG_MONTHLY_V4R4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93576ea-d590-4d0a-b911-0d9aa004a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_name = 'ECCO_L4_SSH_05DEG_MONTHLY_V4R4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344a3f0-329e-4337-b02d-608ac34e5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.path.join('podaac-ops-cumulus-protected/', short_name, '*2015*.nc')\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d50dd-8434-4b3e-a7ab-bf6e341dd62c",
   "metadata": {},
   "source": [
    "Get a list of netCDF files located at the S3 path corresponding to the ECCO V4r4 monthly sea surface height dataset on the 0.5-degree latitude/longitude grid, for year 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_files = fs_s3.glob(bucket)\n",
    "ssh_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-casting",
   "metadata": {},
   "source": [
    "## Direct In-region Access\n",
    "\n",
    "Open with the netCDF files using the s3fs package, then load them all at once into a concatenated `xarray` `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d051a-4479-4771-bb20-461181dc274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = [fs_s3.open(file) for file in ssh_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026748be-ab01-4d6a-9fbe-04697256384d",
   "metadata": {},
   "source": [
    "Create an `xarray dataset` using the `open_mfdataset()` function to \"read in\" all of the netCDF4 files in one call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_ds = xr.open_mfdataset(fileset,\n",
    "                           combine='by_coords',\n",
    "                           mask_and_scale=True,\n",
    "                           decode_cf=True,\n",
    "                           chunks='auto')\n",
    "ssh_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d726f-0b66-484b-ab6e-6ec805ac7cce",
   "metadata": {},
   "source": [
    "Get the `SSH` variable as an `xarray dataarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0185d3d-65ad-47c7-9bfa-5789e0b75e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_da = ssh_ds.SSH\n",
    "ssh_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8076e6d7-55a7-43c2-b867-3ae87f42e4a9",
   "metadata": {},
   "source": [
    "Plot the `SSH` time series using `hvplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb4710-15e8-48ed-b997-fca46782a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_da.hvplot.image(y='latitude', x='longitude', cmap='Viridis',).opts(clim=(ssh_da.attrs['valid_min'][0],ssh_da.attrs['valid_max'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392636d8-27f9-482a-a72d-a29971ebe4f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ee77a-c2ae-4fca-91e9-0a589010feae",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Direct access to ECCO data in S3 (from us-west-2)](https://github.com/podaac/ECCO/blob/main/Data_Access/cloud_direct_access_s3.ipynb)\n",
    "\n",
    "[Data_Access__Direct_S3_Access__PODAAC_ECCO_SSH](https://github.com/NASA-Openscapes/2021-Cloud-Hackathon/blob/main/tutorials/Additional_Resources__Data_Access__Direct_S3_Access__PODAAC_ECCO_SSH.ipynb) using CMR-STAC API to retrieve S3 links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78034da5-a10a-46b4-a711-8a210e2406fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
